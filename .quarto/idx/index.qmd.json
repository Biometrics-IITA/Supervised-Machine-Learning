{"title":"<p style=\"color:black,text-align:center\">Supervised Machine Learning </p>","markdown":{"yaml":{"title":"<p style=\"color:black,text-align:center\">Supervised Machine Learning </p>","author":[{"name":"<font color=#ff6600><b>Biometrics Unit</b></font>","affiliation":"<font color=#ff6600><b>International Institute of Tropical Agriculture (IITA)</b></font>"}]},"headingText":"[**Supervised Learning**]{style=\"color: #234F1E;\"}","containsRefs":false,"markdown":"\n\n\nIn supervised learning, the algorithm is trained using a dataset where each input is matched with the corresponding output. This allows the model to learn how to predict the output for new, unseen inputs. This approach is commonly applied to tasks like classification, regression, and object detection.\n\nIn supervised learning, the machine learning algorithm learns from labeled data. Labeled data is data that has been tagged with a correct answer or classification. In supervised learning, the model learns from labeled examples (input-output pairs). It predicts outputs for new inputs. Classification and regression are common tasks.\n\n![](images/Supervised-learning.png){width=\"50%\"}\n\nSource:geeks for geeks\n\n**Examples**\n\nHere are some examples of supervised learning:\n\n-   **Regression**\n-   **Classification**\n-   **Object detection**\n-   **Spam detection**\n-   **Predictive analytics**\n-   **Medical diagnosis**\n-   **Speech recognition**\n-   **Dimensional Reduction**\n\n## [**Regression Use Case**]{style=\"color: #2C6D26;\"}\n\nLet's consider the `Honey.Wildflower.csv` dataset (13,016 records), this is a dataset in the public domain (Food science) with the following variables:\n\n-   **CS (Color Score):** Represents the color score of the honey sample, ranging from 1.0 to 10.0.\n-   **Density:** Represents the density of the honey sample in grams per cubic centimeter ranging from 1.21 to 1.86.\n-   **WC (Water Content):** Represents the water content in the honey sample, ranging from 12.0% to 25.0%.\n-   **pH:** Represents the pH level of the honey sample, ranging from 2.50 to 7.50.\n-   **EC (Electrical Conductivity):** Represents the electrical conductivity of the honey sample in milli Siemens per centimeter.\n-   **F (Fructose Level):** Represents the fructose level of the honey sample, ranging from 20 to 50.\n-   **G (Glucose Level):** Represents the glucose level of the honey sample, ranging from 20 to 45.\n-   **Pollen_analysis:** Represents the floral source of the honey sample.\n-   **Purity:** Represents the purity of the honey sample, ranging from 0.01 to 1.00.\n-   **Price:** The calculated price of the honey.\n\n### **STEP 1 - Data Import**\n\nThe objective of this exercise is to develop a model that predicts the price of honey\n\nLet's follow our 4 steps to address the objective:\n\n-   STEP 1 - Data pre-processing\n-   STEP 2 - Train the Model\n-   STEP 3 - Evaluate the Model\n-   STEP 4 - Test the Model\n\n```{r}\n#|message=FALSE\nlibrary(tidyverse) #for data import & wrangling\nlibrary(caret) #for model performance evaluation  \ndata <- read_csv(\"Honey.Wildflower.csv\", na = c(\"\", \"NA\"))  \ndata\n```\n\n### **STEP 2 - Data Pre-processing & EDA**\n\n```{r }\nsummary(data)\n```\n\nThe results above shows the summary statistics of each attributes in the dataset\n\n```{r }\n# Visualize the relationship among the attributes  \npsych::pairs.panels(data |> select(-Pollen_analysis),                     \n                    gap = 0,                                       \n                    pch=21)\n```\n\nThe plot shows the distribution of each feature and their relationship with other features. As shown, `purity` is perfectly correlated with the target feature - `price` we will exclude this attribute in our model because it distorts the regression results, making the linear regression coefficients of other features unreliable. Methods like regularization techniques (Lasso & Ridge Regression) which we are not covering in the course could be used to handle such case. We could have dropped those attributes with no strong correlation with `Price` individually, but they could have a combined effect with other attributes. Hence, it's worth keeping them for further analysis.\n\nAlso, looking at the distribution of each attribute, some are skewed while some are not. Let us scale the attributes to have them on uniform scale.\n\n```{r }\n# Feature scaling - exclude the categorical & the purity attribute  \ndata.sc <- scale(data |> \n                   select(-c(Purity, Pollen_analysis)),  \n                 center = TRUE, scale = TRUE) |>\n  as.data.frame()   \nhead(data.sc)\n```\n\n### **STEP 3 - Data partition into training & testing datasets**\n\n```{r }\n# Let's partition the dataset to training & testing datasets using the 70 - 30 split ratio  \nind <- sample(c(TRUE, FALSE), nrow(data.sc),\n              replace = TRUE,                \n              prob = c(0.7, 0.3))    \ntraining <- data.sc[ind==TRUE,]  \ntesting <- data.sc[ind==FALSE,]# Cross check the dimension of the two datasets   \ndim(training)  \ndim(testing)\n```\n\n### **STEP 4 - Build the Model**\n\n-   To build a simple linear regression model, let us consider the `pH` attribute of the dataset given that it has the highest correlation coefficient with the target feature.\n\n```{r }\n# Simple Linear Regression  \nmodel.s <- lm(Price ~ pH, data=training)  \nmodel.s\n```\n\nBefore making use of the model for prediction, we need to assess the significance of the model using the function `summary()`\n\n```{r }\n# Model Summary  \nsummary(model.s)\n```\n\nThe regression coefficient of `pH` in the model is -0.228, which imply that a unit increase in the `pH` level of honey will lead to a significant reduction in the average price of honey by 0.228. The R-squared result showed that about 5% of the variability in the price of honey can be explained by the `pH` of the honey. Also, the residual standard error is 0.972 which implies that the observed price deviate from the predicted value approximately by 0.972 unit on average using `pH` attribute alone.\n\n```{r }\n# Model Diagnostics  \npar(mfrow=c(2,2))  \nplot(model.s)\n```\n\n### **STEP 5 - Model Performance Evaluation**\n\nLet take a look at the Q-Q Residuals & Residual vs Fitted plots, as we can see the data points are not distributed randomly and they do not to align with the diagonal line which imply that the model do not fit the data well. This step is an important step as it helps evaluate how well the model will generalize to an independent dataset. Common metrics used to evaluate regression model performance are **R-squared (R2)**, **Root Mean Squared Error (RMSE)**, and **Mean Absolute Error (MAE)**. These metrics can simply be estimated using the testing dataset or re-sample the data multiple time before computing the metrics.\n\n```{r }\n#Cross Validation Method 1  \npred.s <- predict(model.s, testing)   \ndata.frame( R2 = R2(pred.s, testing$Price ),         \n            RMSE = RMSE(pred.s, testing$Price ),                   \n            MAE = MAE(pred.s, testing$Price ))\n```\n\n```{r }\n#|message = FALSE\n\n# Cross Validation Method 2 - define training control \nset.seed(17)  \ntrain.cv <- trainControl(method = \"repeatedcv\", number = 10,\n            ##number of resampling iteration (we do more than 10 in production )                        \n            repeats = 5)  ##number of repeated k-fold CV to compute\n\n# Train the model  \nmodel.cv.s <- train(Price ~ pH, dat=training,  \n                    method = \"lm\",                  \n                    trControl = train.cv)   \n  \n\n# Make prediction and compute the R2, RMSE and MAE   \npred.cv.s <- predict(model.cv.s, testing) \ndata.frame( R2 = R2(pred.cv.s, testing$Price ),            \n            RMSE = RMSE(pred.cv.s, testing$Price ),            \n            MAE = MAE(pred.cv.s, testing$Price ))\n```\n\nThe correlation between the observed value of the honey price and the predicted value is 5.8% (NB: the higher the better) which is an indication that the model poorly fit the data. Similarly, the same conclusion can be made considering the higher values of the model's RMSE & MAE (NB: lower values are better). This implies that the attribute `pH` alone does not capture the variability in the `Price` of honey in the dataset. Therefore, let's consider fitting multiple linear regression.\n\n## [**Classification Used Case**]{style=\"color: #2C6D26;\"}\n\nThe `agricolae` package in R is primarily designed for agricultural research, providing tools for design, analysis, and multivariate analysis. However, it does not directly focus on classification in the traditional supervised machine learning sense (like you would find in packages such as `caret`, `randomForest`, or `e1071`).\n\nNevertheless, you can use R to perform classification with some basic functions. I can provide you a sample workflow for performing classification using a dataset typically found in agriculture. Here's a basic example using the `iris` dataset (which is not from `agricolae`, but it is a commonly used dataset for demonstrating classification).\n\n### **STEP 1 - Data Import**\n\nFirst, make sure to install the required packages (if you haven't already):\n\n```{r}\n#|eval=FALSE\n#|message=FALSE\n#|include = FALSE\n\n#install.packages(\"agricolae\", repos = \"https://cran.r-project.org/\")  \n#install.packages(\"caret\")  \n#install.packages(\"randomForest\", repos = \"https://cran.r-project.org/\")  ) \n\n# Load required libraries  \nlibrary(agricolae)  \nlibrary(caret) # For easy data splitting and model training  \nsuppressPackageStartupMessages(library(randomForest))\n```\n\n**Load and Inspect the Dataset**\n\nLoad the `iris` dataset from the `agricolae` package and inspect its structure.\n\n```{r}\n# Load the iris dataset  \ndata(iris)  \n# Inspect the dataset   \nhead(iris)  \n```\n\n### **Step 2 - Data Preprocessing**\n\n```{r}\n# View the structure of the dataset  \nstr(iris)   \nsummary(iris)\n```\n\n### **Step 3 - Data partition into training and testing datasets**\n\nSplit the dataset into training (70%) and testing (30%)\n\n```{r}\nset.seed(123) \n# For reproducibility  \ntrainIndex <- createDataPartition(iris$Species, p = .7, list = FALSE, times = 1)  \nirisTrain <- iris[trainIndex, ]  \nirisTest <- iris[-trainIndex, ]\n```\n\n### **Step 4 - Build the model**\n\n```{r}\n# Fit a classification model using Random Forest \nmodel_rf <- train(Species ~ ., data = irisTrain, method = \"rf\")   \n# Model summary  \nprint(model_rf) \n```\n\n**Results Across Tuning Parameters:**\n\n**mtry:** In Random Forest, 'mtry' refers to the number of features randomly selected at each split in the decision trees. The results presented include three values for mtry (2, 3, and 4).\n\nFor mtry = 2, the model achieved the highest accuracy of 0.9488 and a Kappa statistic of 0.9221.\n\nFor mtry = 3, the accuracy was slightly lower at 0.9469, with a Kappa of 0.9192.\n\nFor mtry = 4, the accuracy dropped to 0.9427, with a Kappa of 0.9129.\n\nOptimal mtry Selected: The model selected for final use is mtry = 2, which had the highest accuracy. This indicates that selecting two features for each decision tree split was the most effective in classifying the Iris species in this scenario. Interpretation of Performance Metrics:\n\n**Accuracy:** An accuracy of around 94.9% suggests that the model correctly classifies about 94.9% of the instances in a typical scenario. This is quite high, especially for a classification problem with three classes.\n\n**Kappa Statistic:** The Kappa statistic is a measure of agreement between the predicted and observed classifications. A Kappa value above 0.9 (as seen here) indicates almost perfect agreement, suggesting that the model's predictions are very reliable. Conclusion and Further Considerations: Given the high accuracy and Kappa scores, the Random Forest model seems to perform exceptionally well on this dataset.\n\n### **Step 5 - Evaluate Model Parameter**\n\n```{r}\n# Make predictions on the test set  \npredictions <- predict(model_rf, irisTest)   \n# Confusion matrix to evaluate the model  \nconfusion_matrix <- table(irisTest$Species, predictions) \nprint(confusion_matrix)  \n```\n\n**Accuracy calculation**\n\n```{r}\n# Calculate accuracy    \naccuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)   \nprint(paste(\"Accuracy:\", round(accuracy, 4)))\n```\n\n**Feature Checking**\n\n```{r}\n#|eval=FALSE\n#|message=FALSE\n# Example of fitting a random forest model \nlibrary(randomForest)  \nrf_model <- randomForest(Species ~ ., data = iris)   \n# Check the class of the model object  \nclass(rf_model) \n```\n\n### Explanation:\n\n1.  **Loading Libraries**: We load the `agricolae` (for agricultural data analysis) and `caret` (for classification and other machine learning tasks) libraries.\n\n2.  **Dataset**: We use `iris`, a built-in dataset in R which contains information about different species of iris flowers based on sepal and petal dimensions.\n\n3.  **Data Splitting**: The dataset is split into training and test sets to evaluate the performance of our model.\n\n4.  **Model Training**: We train a Random Forest classifier on the training dataset. The `Species` column is our target variable, and the rest are features.\n\n5.  **Predictions**: We use our trained model to make predictions on the test dataset.\n\n6.  **Confusion Matrix**: Finally, we evaluate our model's performance using a confusion matrix, which shows how many instances were correctly predicted by the model.\n","srcMarkdownNoYaml":"\n\n# [**Supervised Learning**]{style=\"color: #234F1E;\"}\n\nIn supervised learning, the algorithm is trained using a dataset where each input is matched with the corresponding output. This allows the model to learn how to predict the output for new, unseen inputs. This approach is commonly applied to tasks like classification, regression, and object detection.\n\nIn supervised learning, the machine learning algorithm learns from labeled data. Labeled data is data that has been tagged with a correct answer or classification. In supervised learning, the model learns from labeled examples (input-output pairs). It predicts outputs for new inputs. Classification and regression are common tasks.\n\n![](images/Supervised-learning.png){width=\"50%\"}\n\nSource:geeks for geeks\n\n**Examples**\n\nHere are some examples of supervised learning:\n\n-   **Regression**\n-   **Classification**\n-   **Object detection**\n-   **Spam detection**\n-   **Predictive analytics**\n-   **Medical diagnosis**\n-   **Speech recognition**\n-   **Dimensional Reduction**\n\n## [**Regression Use Case**]{style=\"color: #2C6D26;\"}\n\nLet's consider the `Honey.Wildflower.csv` dataset (13,016 records), this is a dataset in the public domain (Food science) with the following variables:\n\n-   **CS (Color Score):** Represents the color score of the honey sample, ranging from 1.0 to 10.0.\n-   **Density:** Represents the density of the honey sample in grams per cubic centimeter ranging from 1.21 to 1.86.\n-   **WC (Water Content):** Represents the water content in the honey sample, ranging from 12.0% to 25.0%.\n-   **pH:** Represents the pH level of the honey sample, ranging from 2.50 to 7.50.\n-   **EC (Electrical Conductivity):** Represents the electrical conductivity of the honey sample in milli Siemens per centimeter.\n-   **F (Fructose Level):** Represents the fructose level of the honey sample, ranging from 20 to 50.\n-   **G (Glucose Level):** Represents the glucose level of the honey sample, ranging from 20 to 45.\n-   **Pollen_analysis:** Represents the floral source of the honey sample.\n-   **Purity:** Represents the purity of the honey sample, ranging from 0.01 to 1.00.\n-   **Price:** The calculated price of the honey.\n\n### **STEP 1 - Data Import**\n\nThe objective of this exercise is to develop a model that predicts the price of honey\n\nLet's follow our 4 steps to address the objective:\n\n-   STEP 1 - Data pre-processing\n-   STEP 2 - Train the Model\n-   STEP 3 - Evaluate the Model\n-   STEP 4 - Test the Model\n\n```{r}\n#|message=FALSE\nlibrary(tidyverse) #for data import & wrangling\nlibrary(caret) #for model performance evaluation  \ndata <- read_csv(\"Honey.Wildflower.csv\", na = c(\"\", \"NA\"))  \ndata\n```\n\n### **STEP 2 - Data Pre-processing & EDA**\n\n```{r }\nsummary(data)\n```\n\nThe results above shows the summary statistics of each attributes in the dataset\n\n```{r }\n# Visualize the relationship among the attributes  \npsych::pairs.panels(data |> select(-Pollen_analysis),                     \n                    gap = 0,                                       \n                    pch=21)\n```\n\nThe plot shows the distribution of each feature and their relationship with other features. As shown, `purity` is perfectly correlated with the target feature - `price` we will exclude this attribute in our model because it distorts the regression results, making the linear regression coefficients of other features unreliable. Methods like regularization techniques (Lasso & Ridge Regression) which we are not covering in the course could be used to handle such case. We could have dropped those attributes with no strong correlation with `Price` individually, but they could have a combined effect with other attributes. Hence, it's worth keeping them for further analysis.\n\nAlso, looking at the distribution of each attribute, some are skewed while some are not. Let us scale the attributes to have them on uniform scale.\n\n```{r }\n# Feature scaling - exclude the categorical & the purity attribute  \ndata.sc <- scale(data |> \n                   select(-c(Purity, Pollen_analysis)),  \n                 center = TRUE, scale = TRUE) |>\n  as.data.frame()   \nhead(data.sc)\n```\n\n### **STEP 3 - Data partition into training & testing datasets**\n\n```{r }\n# Let's partition the dataset to training & testing datasets using the 70 - 30 split ratio  \nind <- sample(c(TRUE, FALSE), nrow(data.sc),\n              replace = TRUE,                \n              prob = c(0.7, 0.3))    \ntraining <- data.sc[ind==TRUE,]  \ntesting <- data.sc[ind==FALSE,]# Cross check the dimension of the two datasets   \ndim(training)  \ndim(testing)\n```\n\n### **STEP 4 - Build the Model**\n\n-   To build a simple linear regression model, let us consider the `pH` attribute of the dataset given that it has the highest correlation coefficient with the target feature.\n\n```{r }\n# Simple Linear Regression  \nmodel.s <- lm(Price ~ pH, data=training)  \nmodel.s\n```\n\nBefore making use of the model for prediction, we need to assess the significance of the model using the function `summary()`\n\n```{r }\n# Model Summary  \nsummary(model.s)\n```\n\nThe regression coefficient of `pH` in the model is -0.228, which imply that a unit increase in the `pH` level of honey will lead to a significant reduction in the average price of honey by 0.228. The R-squared result showed that about 5% of the variability in the price of honey can be explained by the `pH` of the honey. Also, the residual standard error is 0.972 which implies that the observed price deviate from the predicted value approximately by 0.972 unit on average using `pH` attribute alone.\n\n```{r }\n# Model Diagnostics  \npar(mfrow=c(2,2))  \nplot(model.s)\n```\n\n### **STEP 5 - Model Performance Evaluation**\n\nLet take a look at the Q-Q Residuals & Residual vs Fitted plots, as we can see the data points are not distributed randomly and they do not to align with the diagonal line which imply that the model do not fit the data well. This step is an important step as it helps evaluate how well the model will generalize to an independent dataset. Common metrics used to evaluate regression model performance are **R-squared (R2)**, **Root Mean Squared Error (RMSE)**, and **Mean Absolute Error (MAE)**. These metrics can simply be estimated using the testing dataset or re-sample the data multiple time before computing the metrics.\n\n```{r }\n#Cross Validation Method 1  \npred.s <- predict(model.s, testing)   \ndata.frame( R2 = R2(pred.s, testing$Price ),         \n            RMSE = RMSE(pred.s, testing$Price ),                   \n            MAE = MAE(pred.s, testing$Price ))\n```\n\n```{r }\n#|message = FALSE\n\n# Cross Validation Method 2 - define training control \nset.seed(17)  \ntrain.cv <- trainControl(method = \"repeatedcv\", number = 10,\n            ##number of resampling iteration (we do more than 10 in production )                        \n            repeats = 5)  ##number of repeated k-fold CV to compute\n\n# Train the model  \nmodel.cv.s <- train(Price ~ pH, dat=training,  \n                    method = \"lm\",                  \n                    trControl = train.cv)   \n  \n\n# Make prediction and compute the R2, RMSE and MAE   \npred.cv.s <- predict(model.cv.s, testing) \ndata.frame( R2 = R2(pred.cv.s, testing$Price ),            \n            RMSE = RMSE(pred.cv.s, testing$Price ),            \n            MAE = MAE(pred.cv.s, testing$Price ))\n```\n\nThe correlation between the observed value of the honey price and the predicted value is 5.8% (NB: the higher the better) which is an indication that the model poorly fit the data. Similarly, the same conclusion can be made considering the higher values of the model's RMSE & MAE (NB: lower values are better). This implies that the attribute `pH` alone does not capture the variability in the `Price` of honey in the dataset. Therefore, let's consider fitting multiple linear regression.\n\n## [**Classification Used Case**]{style=\"color: #2C6D26;\"}\n\nThe `agricolae` package in R is primarily designed for agricultural research, providing tools for design, analysis, and multivariate analysis. However, it does not directly focus on classification in the traditional supervised machine learning sense (like you would find in packages such as `caret`, `randomForest`, or `e1071`).\n\nNevertheless, you can use R to perform classification with some basic functions. I can provide you a sample workflow for performing classification using a dataset typically found in agriculture. Here's a basic example using the `iris` dataset (which is not from `agricolae`, but it is a commonly used dataset for demonstrating classification).\n\n### **STEP 1 - Data Import**\n\nFirst, make sure to install the required packages (if you haven't already):\n\n```{r}\n#|eval=FALSE\n#|message=FALSE\n#|include = FALSE\n\n#install.packages(\"agricolae\", repos = \"https://cran.r-project.org/\")  \n#install.packages(\"caret\")  \n#install.packages(\"randomForest\", repos = \"https://cran.r-project.org/\")  ) \n\n# Load required libraries  \nlibrary(agricolae)  \nlibrary(caret) # For easy data splitting and model training  \nsuppressPackageStartupMessages(library(randomForest))\n```\n\n**Load and Inspect the Dataset**\n\nLoad the `iris` dataset from the `agricolae` package and inspect its structure.\n\n```{r}\n# Load the iris dataset  \ndata(iris)  \n# Inspect the dataset   \nhead(iris)  \n```\n\n### **Step 2 - Data Preprocessing**\n\n```{r}\n# View the structure of the dataset  \nstr(iris)   \nsummary(iris)\n```\n\n### **Step 3 - Data partition into training and testing datasets**\n\nSplit the dataset into training (70%) and testing (30%)\n\n```{r}\nset.seed(123) \n# For reproducibility  \ntrainIndex <- createDataPartition(iris$Species, p = .7, list = FALSE, times = 1)  \nirisTrain <- iris[trainIndex, ]  \nirisTest <- iris[-trainIndex, ]\n```\n\n### **Step 4 - Build the model**\n\n```{r}\n# Fit a classification model using Random Forest \nmodel_rf <- train(Species ~ ., data = irisTrain, method = \"rf\")   \n# Model summary  \nprint(model_rf) \n```\n\n**Results Across Tuning Parameters:**\n\n**mtry:** In Random Forest, 'mtry' refers to the number of features randomly selected at each split in the decision trees. The results presented include three values for mtry (2, 3, and 4).\n\nFor mtry = 2, the model achieved the highest accuracy of 0.9488 and a Kappa statistic of 0.9221.\n\nFor mtry = 3, the accuracy was slightly lower at 0.9469, with a Kappa of 0.9192.\n\nFor mtry = 4, the accuracy dropped to 0.9427, with a Kappa of 0.9129.\n\nOptimal mtry Selected: The model selected for final use is mtry = 2, which had the highest accuracy. This indicates that selecting two features for each decision tree split was the most effective in classifying the Iris species in this scenario. Interpretation of Performance Metrics:\n\n**Accuracy:** An accuracy of around 94.9% suggests that the model correctly classifies about 94.9% of the instances in a typical scenario. This is quite high, especially for a classification problem with three classes.\n\n**Kappa Statistic:** The Kappa statistic is a measure of agreement between the predicted and observed classifications. A Kappa value above 0.9 (as seen here) indicates almost perfect agreement, suggesting that the model's predictions are very reliable. Conclusion and Further Considerations: Given the high accuracy and Kappa scores, the Random Forest model seems to perform exceptionally well on this dataset.\n\n### **Step 5 - Evaluate Model Parameter**\n\n```{r}\n# Make predictions on the test set  \npredictions <- predict(model_rf, irisTest)   \n# Confusion matrix to evaluate the model  \nconfusion_matrix <- table(irisTest$Species, predictions) \nprint(confusion_matrix)  \n```\n\n**Accuracy calculation**\n\n```{r}\n# Calculate accuracy    \naccuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)   \nprint(paste(\"Accuracy:\", round(accuracy, 4)))\n```\n\n**Feature Checking**\n\n```{r}\n#|eval=FALSE\n#|message=FALSE\n# Example of fitting a random forest model \nlibrary(randomForest)  \nrf_model <- randomForest(Species ~ ., data = iris)   \n# Check the class of the model object  \nclass(rf_model) \n```\n\n### Explanation:\n\n1.  **Loading Libraries**: We load the `agricolae` (for agricultural data analysis) and `caret` (for classification and other machine learning tasks) libraries.\n\n2.  **Dataset**: We use `iris`, a built-in dataset in R which contains information about different species of iris flowers based on sepal and petal dimensions.\n\n3.  **Data Splitting**: The dataset is split into training and test sets to evaluate the performance of our model.\n\n4.  **Model Training**: We train a Random Forest classifier on the training dataset. The `Species` column is our target variable, and the rest are features.\n\n5.  **Predictions**: We use our trained model to make predictions on the test dataset.\n\n6.  **Confusion Matrix**: Finally, we evaluate our model's performance using a confusion matrix, which shows how many instances were correctly predicted by the model.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.555","editor":"visual","theme":"cosmo","title":"<p style=\"color:black,text-align:center\">Supervised Machine Learning </p>","author":[{"name":"<font color=#ff6600><b>Biometrics Unit</b></font>","affiliation":"<font color=#ff6600><b>International Institute of Tropical Agriculture (IITA)</b></font>"}]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}
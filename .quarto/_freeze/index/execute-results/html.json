{
  "hash": "5f4a809b51cc2b7fdf1fda6d1fc360a6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"<p style=\\\"color:black,text-align:center\\\">Supervised Machine Learning </p>\"\nauthor:\n  - name: <font color=#ff6600><b>Biometrics Unit</b></font>      \n    affiliation: <font color=#ff6600><b>International Institute of Tropical Agriculture (IITA)</b></font>\n---\n\n\n# [**Supervised Learning**]{style=\"color: #234F1E;\"}\n\nIn supervised learning, the algorithm is trained using a dataset where each input is matched with the corresponding output. This allows the model to learn how to predict the output for new, unseen inputs. This approach is commonly applied to tasks like classification, regression, and object detection.\n\nIn supervised learning, the machine learning algorithm learns from labeled data. Labeled data is data that has been tagged with a correct answer or classification. In supervised learning, the model learns from labeled examples (input-output pairs). It predicts outputs for new inputs. Classification and regression are common tasks.\n\n![](images/Supervised-learning.png){width=\"50%\"}\n\nSource:geeks for geeks\n\n**Examples**\n\nHere are some examples of supervised learning:\n\n-   **Regression**\n-   **Classification**\n-   **Object detection**\n-   **Spam detection**\n-   **Predictive analytics**\n-   **Medical diagnosis**\n-   **Speech recognition**\n-   **Dimensional Reduction**\n\n## [**Regression Use Case**]{style=\"color: #2C6D26;\"}\n\nLet's consider the `Honey.Wildflower.csv` dataset (13,016 records), this is a dataset in the public domain (Food science) with the following variables:\n\n-   **CS (Color Score):** Represents the color score of the honey sample, ranging from 1.0 to 10.0.\n-   **Density:** Represents the density of the honey sample in grams per cubic centimeter ranging from 1.21 to 1.86.\n-   **WC (Water Content):** Represents the water content in the honey sample, ranging from 12.0% to 25.0%.\n-   **pH:** Represents the pH level of the honey sample, ranging from 2.50 to 7.50.\n-   **EC (Electrical Conductivity):** Represents the electrical conductivity of the honey sample in milli Siemens per centimeter.\n-   **F (Fructose Level):** Represents the fructose level of the honey sample, ranging from 20 to 50.\n-   **G (Glucose Level):** Represents the glucose level of the honey sample, ranging from 20 to 45.\n-   **Pollen_analysis:** Represents the floral source of the honey sample.\n-   **Purity:** Represents the purity of the honey sample, ranging from 0.01 to 1.00.\n-   **Price:** The calculated price of the honey.\n\n### **STEP 1 - Data Import**\n\nThe objective of this exercise is to develop a model that predicts the price of honey\n\nLet's follow our 4 steps to address the objective:\n\n-   STEP 1 - Data pre-processing\n-   STEP 2 - Train the Model\n-   STEP 3 - Evaluate the Model\n-   STEP 4 - Test the Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#|message=FALSE\nlibrary(tidyverse) #for data import & wrangling\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(caret) #for model performance evaluation  \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: lattice\n\nAttaching package: 'caret'\n\nThe following object is masked from 'package:purrr':\n\n    lift\n```\n\n\n:::\n\n```{.r .cell-code}\ndata <- read_csv(\"Honey.Wildflower.csv\", na = c(\"\", \"NA\"))  \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 13016 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): Pollen_analysis\ndbl (10): CS, Density, WC, pH, EC, F, G, Viscosity, Purity, Price\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\ndata\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 13,016 × 11\n      CS Density    WC    pH    EC     F     G Pollen_analysis Viscosity Purity\n   <dbl>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <chr>               <dbl>  <dbl>\n 1  3       1.53  13.6  6.86  0.72  42.5  29.0 Wildflower          2675.   0.66\n 2  8.79    1.6   14.5  3.11  0.82  29.5  32.1 Wildflower          8442.   0.82\n 3  7.07    1.5   16.2  6.42  0.89  47.0  40.5 Wildflower          2095.   0.92\n 4  3.93    1.47  22.2  4.09  0.79  23.9  36.8 Wildflower          4053.   0.82\n 5  6.25    1.35  16.7  4.53  0.76  25.1  37.3 Wildflower          1822.   1   \n 6  4.8     1.71  22.2  5.68  0.78  30.1  23.4 Wildflower          4733.   0.97\n 7  6.58    1.54  15.4  3.45  0.7   49.3  24.5 Wildflower          7032.   1   \n 8  7.59    1.83  23.2  2.65  0.79  26.4  32.2 Wildflower          8518.   0.66\n 9  2.25    1.29  19.6  6.63  0.81  38.2  27.6 Wildflower          6782.   0.68\n10  3.01    1.47  16.4  4.92  0.89  31.3  25.3 Wildflower          3868.   0.84\n# ℹ 13,006 more rows\n# ℹ 1 more variable: Price <dbl>\n```\n\n\n:::\n:::\n\n\n### **STEP 2 - Data Pre-processing & EDA**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       CS            Density            WC              pH       \n Min.   : 1.000   Min.   :1.210   Min.   :12.00   Min.   :2.500  \n 1st Qu.: 3.230   1st Qu.:1.380   1st Qu.:15.29   1st Qu.:3.790  \n Median : 5.530   Median :1.540   Median :18.49   Median :5.020  \n Mean   : 5.492   Mean   :1.537   Mean   :18.51   Mean   :5.012  \n 3rd Qu.: 7.680   3rd Qu.:1.700   3rd Qu.:21.76   3rd Qu.:6.250  \n Max.   :10.000   Max.   :1.860   Max.   :25.00   Max.   :7.500  \n       EC               F               G         Pollen_analysis   \n Min.   :0.7000   Min.   :20.00   Min.   :20.01   Length:13016      \n 1st Qu.:0.7500   1st Qu.:27.59   1st Qu.:26.36   Class :character  \n Median :0.8000   Median :34.93   Median :32.78   Mode  :character  \n Mean   :0.8009   Mean   :34.95   Mean   :32.64                     \n 3rd Qu.:0.8500   3rd Qu.:42.37   3rd Qu.:38.95                     \n Max.   :0.9000   Max.   :50.00   Max.   :45.00                     \n   Viscosity        Purity           Price      \n Min.   :1500   Min.   :0.6100   Min.   :196.2  \n 1st Qu.:3631   1st Qu.:0.6600   1st Qu.:213.0  \n Median :5800   Median :0.8200   Median :264.5  \n Mean   :5752   Mean   :0.8263   Mean   :265.8  \n 3rd Qu.:7876   3rd Qu.:0.9700   3rd Qu.:312.8  \n Max.   :9999   Max.   :1.0000   Max.   :321.9  \n```\n\n\n:::\n:::\n\n\nThe results above shows the summary statistics of each attributes in the dataset\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize the relationship among the attributes  \npsych::pairs.panels(data |> select(-Pollen_analysis),                     \n                    gap = 0,                                       \n                    pch=21)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nThe plot shows the distribution of each feature and their relationship with other features. As shown, `purity` is perfectly correlated with the target feature - `price` we will exclude this attribute in our model because it distorts the regression results, making the linear regression coefficients of other features unreliable. Methods like regularization techniques (Lasso & Ridge Regression) which we are not covering in the course could be used to handle such case. We could have dropped those attributes with no strong correlation with `Price` individually, but they could have a combined effect with other attributes. Hence, it's worth keeping them for further analysis.\n\nAlso, looking at the distribution of each attribute, some are skewed while some are not. Let us scale the attributes to have them on uniform scale.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Feature scaling - exclude the categorical & the purity attribute  \ndata.sc <- scale(data |> \n                   select(-c(Purity, Pollen_analysis)),  \n                 center = TRUE, scale = TRUE) |>\n  as.data.frame()   \nhead(data.sc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          CS     Density         WC         pH         EC          F\n1 -0.9657555 -0.03848956 -1.3201939  1.2898170 -1.3935623  0.8803455\n2  1.2781196  0.33323622 -1.0784491 -1.3273507  0.3293297 -0.6370040\n3  0.6115453 -0.19780061 -0.6137620  0.9827360  1.5353541  1.3993163\n4 -0.6053403 -0.35711166  0.9790673 -0.6433975 -0.1875379 -1.2874629\n5  0.2937599 -0.99435587 -0.4982618 -0.3363165 -0.7044055 -1.1501568\n6 -0.2681778  0.91737674  0.9951836  0.4662816 -0.3598271 -0.5671873\n            G  Viscosity      Price\n1 -0.50946018 -1.2527065 -1.1746670\n2 -0.06941726  1.0950833 -0.0289733\n3  1.08241924 -1.4889857  0.6729392\n4  0.57478351 -0.6918303 -0.0289733\n5  0.64513520 -1.6001065  1.2458972\n6 -1.27505210 -0.4149892  1.0095548\n```\n\n\n:::\n:::\n\n\n### **STEP 3 - Data partition into training & testing datasets**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Let's partition the dataset to training & testing datasets using the 70 - 30 split ratio  \nind <- sample(c(TRUE, FALSE), nrow(data.sc),\n              replace = TRUE,                \n              prob = c(0.7, 0.3))    \ntraining <- data.sc[ind==TRUE,]  \ntesting <- data.sc[ind==FALSE,]# Cross check the dimension of the two datasets   \ndim(training)  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 9105    9\n```\n\n\n:::\n\n```{.r .cell-code}\ndim(testing)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3911    9\n```\n\n\n:::\n:::\n\n\n### **STEP 4 - Build the Model**\n\n-   To build a simple linear regression model, let us consider the `pH` attribute of the dataset given that it has the highest correlation coefficient with the target feature.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simple Linear Regression  \nmodel.s <- lm(Price ~ pH, data=training)  \nmodel.s\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Price ~ pH, data = training)\n\nCoefficients:\n(Intercept)           pH  \n  -0.003484    -0.225011  \n```\n\n\n:::\n:::\n\n\nBefore making use of the model for prediction, we need to assess the significance of the model using the function `summary()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Model Summary  \nsummary(model.s)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Price ~ pH, data = training)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9333 -0.9391 -0.1467  1.0230  1.6401 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.003484   0.010199  -0.342    0.733    \npH          -0.225011   0.010182 -22.098   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9732 on 9103 degrees of freedom\nMultiple R-squared:  0.05091,\tAdjusted R-squared:  0.05081 \nF-statistic: 488.3 on 1 and 9103 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\nThe regression coefficient of `pH` in the model is -0.228, which imply that a unit increase in the `pH` level of honey will lead to a significant reduction in the average price of honey by 0.228. The R-squared result showed that about 5% of the variability in the price of honey can be explained by the `pH` of the honey. Also, the residual standard error is 0.972 which implies that the observed price deviate from the predicted value approximately by 0.972 unit on average using `pH` attribute alone.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Model Diagnostics  \npar(mfrow=c(2,2))  \nplot(model.s)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nA few possible problems with the regression model are shown by the diagnostic plots: non-normality of residuals, potential heteroscedasticity, and possible misspecifications of the model (such as missing variables or non-linearity). Reexamining the model assumptions or altering the data would be beneficial.\n\n### **STEP 5 - Model Performance Evaluation**\n\nLet take a look at the Q-Q Residuals & Residual vs Fitted plots, as we can see the data points are not distributed randomly and they do not to align with the diagonal line which imply that the model do not fit the data well. This step is an important step as it helps evaluate how well the model will generalize to an independent dataset. Common metrics used to evaluate regression model performance are **R-squared (R2)**, **Root Mean Squared Error (RMSE)**, and **Mean Absolute Error (MAE)**. These metrics can simply be estimated using the testing dataset or re-sample the data multiple time before computing the metrics.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Cross Validation Method 1  \npred.s <- predict(model.s, testing)   \ndata.frame( R2 = R2(pred.s, testing$Price ),         \n            RMSE = RMSE(pred.s, testing$Price ),                   \n            MAE = MAE(pred.s, testing$Price ))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         R2      RMSE       MAE\n1 0.0601789 0.9722118 0.8669958\n```\n\n\n:::\n:::\n\n\nR- squared (0.0460) indicates that 4.6% of the variation in the the price of honey is determined by the pH level of honey.\n\nA Root Mean Square Error (RMSE) value (0.9746) which is close to 1 suggests that the typical error in the model's predictions is around 0.97 units, indicating that the model is not very accurate. Ideally, you want RMSE to be as low as possible.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#|message = FALSE\n\n# Cross Validation Method 2 - define training control \nset.seed(17)  \ntrain.cv <- trainControl(method = \"repeatedcv\", number = 10,\n            ##number of resampling iteration (we do more than 10 in production )                        \n            repeats = 5)  ##number of repeated k-fold CV to compute\n\n# Train the model  \nmodel.cv.s <- train(Price ~ pH, dat=training,  \n                    method = \"lm\",                  \n                    trControl = train.cv)   \n  \n\n# Make prediction and compute the R2, RMSE and MAE   \npred.cv.s <- predict(model.cv.s, testing) \ndata.frame( R2 = R2(pred.cv.s, testing$Price ),            \n            RMSE = RMSE(pred.cv.s, testing$Price ),            \n            MAE = MAE(pred.cv.s, testing$Price ))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         R2      RMSE       MAE\n1 0.0601789 0.9722118 0.8669958\n```\n\n\n:::\n:::\n\n\nThe correlation between the observed value of the honey price and the predicted value is 5.8% (NB: the higher the better) which is an indication that the model poorly fit the data. Similarly, the same conclusion can be made considering the higher values of the model's RMSE & MAE (NB: lower values are better). This implies that the attribute `pH` alone does not capture the variability in the `Price` of honey in the dataset. Therefore, let's consider fitting multiple linear regression with other attributes, that way we can determine which of these attributes affecte the variability in price of honey most.\n\n## [**Classification Used Case**]{style=\"color: #2C6D26;\"}\n\nThe `agricolae` package in R is primarily designed for agricultural research, providing tools for design, analysis, and multivariate analysis. However, it does not directly focus on classification in the traditional supervised machine learning sense (like you would find in packages such as `caret`, `randomForest`, or `e1071`).\n\nNevertheless, you can use R to perform classification with some basic functions. I can provide you a sample workflow for performing classification using a dataset typically found in agriculture. Here's a basic example using the `iris` dataset (which is not from `agricolae`, but it is a commonly used dataset for demonstrating classification).\n\n### **STEP 1 - Data Import**\n\nFirst, make sure to install the required packages (if you haven't already):\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#|eval=FALSE\n#|message=FALSE\n#|include = FALSE\n\n#install.packages(\"agricolae\", repos = \"https://cran.r-project.org/\")  \n#install.packages(\"caret\")  \n#install.packages(\"randomForest\", repos = \"https://cran.r-project.org/\")  ) \n\n# Load required libraries  \nlibrary(agricolae)  \nlibrary(caret) # For easy data splitting and model training  \nsuppressPackageStartupMessages(library(randomForest))\n```\n:::\n\n\n**Load and Inspect the Dataset**\n\nLoad the `iris` dataset from the `agricolae` package and inspect its structure.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the iris dataset  \ndata(iris)  \n# Inspect the dataset   \nhead(iris)  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n```\n\n\n:::\n:::\n\n\n### **Step 2 - Data Preprocessing**\n\nWe check the structure and summary of the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# View the structure of the dataset  \nstr(iris)   \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(iris)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n```\n\n\n:::\n:::\n\n\n### **Step 3 - Data partition into training and testing datasets**\n\nSplit the dataset into training (70%) and testing (30%)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123) \n# For reproducibility  \ntrainIndex <- createDataPartition(iris$Species, p = .7, list = FALSE, times = 1)  \nirisTrain <- iris[trainIndex, ]  \nirisTest <- iris[-trainIndex, ]\n```\n:::\n\n\n### **Step 4 - Build the model**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit a classification model using Random Forest \nmodel_rf <- train(Species ~ ., data = irisTrain, method = \"rf\")   \n# Model summary  \nprint(model_rf) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRandom Forest \n\n105 samples\n  4 predictor\n  3 classes: 'setosa', 'versicolor', 'virginica' \n\nNo pre-processing\nResampling: Bootstrapped (25 reps) \nSummary of sample sizes: 105, 105, 105, 105, 105, 105, ... \nResampling results across tuning parameters:\n\n  mtry  Accuracy   Kappa    \n  2     0.9488042  0.9221447\n  3     0.9468995  0.9192369\n  4     0.9427645  0.9129347\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was mtry = 2.\n```\n\n\n:::\n:::\n\n\n**Results Across Tuning Parameters:**\n\n**mtry:** In Random Forest, 'mtry' refers to the number of features randomly selected at each split in the decision trees. The results presented include three values for mtry (2, 3, and 4).\n\nFor mtry = 2, the model achieved the highest accuracy of 0.9488 and a Kappa statistic of 0.9221.\n\nFor mtry = 3, the accuracy was slightly lower at 0.9469, with a Kappa of 0.9192.\n\nFor mtry = 4, the accuracy dropped to 0.9427, with a Kappa of 0.9129.\n\nOptimal mtry Selected: The model selected for final use is mtry = 2, which had the highest accuracy. This indicates that selecting two features for each decision tree split was the most effective in classifying the Iris species in this scenario. Interpretation of Performance Metrics:\n\n**Accuracy:** An accuracy of around 94.9% suggests that the model correctly classifies about 94.9% of the instances in a typical scenario. This is quite high, especially for a classification problem with three classes.\n\n**Kappa Statistic:** The Kappa statistic is a measure of agreement between the predicted and observed classifications. A Kappa value above 0.9 (as seen here) indicates almost perfect agreement, suggesting that the model's predictions are very reliable. Conclusion and Further Considerations: Given the high accuracy and Kappa scores, the Random Forest model seems to perform exceptionally well on this dataset.\n\n### **Step 5 - Evaluate Model Parameter**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Make predictions on the test set  \npredictions <- predict(model_rf, irisTest)   \n# Confusion matrix to evaluate the model  \nconfusion_matrix <- table(irisTest$Species, predictions) \nprint(confusion_matrix)  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            predictions\n             setosa versicolor virginica\n  setosa         15          0         0\n  versicolor      0         14         1\n  virginica       0          2        13\n```\n\n\n:::\n:::\n\n\n-   **Setosa**: The model perfectly predicted all 15 setosa samples (100% accuracy for this class).\n\n-   **Versicolor**: The model predicted 14 out of 15 versicolor samples correctly, with one being misclassified as virginica.\n\n-   **Virginica**: The model predicted 13 out of 15 virginica samples correctly, with two being misclassified as versicolor.\n\n**Accuracy calculation**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate accuracy    \naccuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)   \nprint(paste(\"Accuracy:\", round(accuracy, 4)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Accuracy: 0.9333\"\n```\n\n\n:::\n:::\n\n\nIt shows 93% accuracy of the model.\n\n#### **Feature Checking**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#|eval=FALSE\n#|message=FALSE\n# Example of fitting a random forest model \nlibrary(randomForest)\nrf_model <- randomForest(Species ~ ., data = iris)   \n# Check the class of the model object  \nclass(rf_model) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"randomForest.formula\" \"randomForest\"        \n```\n\n\n:::\n:::\n\n\n### Explanation:\n\n1.  **Loading Libraries**: We load the `agricolae` (for agricultural data analysis) and `caret` (for classification and other machine learning tasks) libraries.\n\n2.  **Dataset**: We use `iris`, a built-in dataset in R which contains information about different species of iris flowers based on sepal and petal dimensions.\n\n3.  **Data Splitting**: The dataset is split into training and test sets to evaluate the performance of our model.\n\n4.  **Model Training**: We train a Random Forest classifier on the training dataset. The `Species` column is our target variable, and the rest are features.\n\n5.  **Predictions**: We use our trained model to make predictions on the test dataset.\n\n6.  **Confusion Matrix**: Finally, we evaluate our model's performance using a confusion matrix, which shows how many instances were correctly predicted by the model.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}